# -*- coding: utf-8 -*-
"""Optical_Character_Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/113Zr7SCCSUzcxmpEgw7YumgWCRnK6Cxh
"""

# Don't forget to include google-cloud-vision and google-cloud-automl to requirements.txt
# !pip install google-cloud-vision
#
# pip install google-cloud-automl

import pandas as pd
import re
import cv2

import os, io
from google.cloud import vision

import firebase_admin
from firebase_admin import credentials
from firebase_admin import firestore

import numpy as np
import tensorflow as tf
import time
import sys
# from google.cloud import automl

# AutoML - bbox model path
bbox_model_path = './automl-bbox/tflite_ver2/model.tflite'
bbox = tf.lite.Interpreter(bbox_model_path)
bbox.allocate_tensors()
input_details = bbox.get_input_details()
output_details = bbox.get_output_details()
input_index = input_details[0]['index']


def read_image(imgpath):
  img = cv2.imdecode(np.fromstring(imgpath, np.uint8), cv2.IMREAD_UNCHANGED)
  is_success, im_buf_arr = cv2.imencode(".jpg", img)
  content = im_buf_arr.tobytes()

  return content

# 'content' is base-64-encoded image data.
def get_prediction(imgpath, model):
  # prediction_client = automl.PredictionServiceClient() # Ganti jadi modelnya kalo udah jdi format lain

  # name = 'projects/{}/locations/us-central1/models/{}'.format(project_id, model_id)

  # payload = {'image': {'image_bytes': content }}
  # params = {}
  # request = prediction_client.predict(name=name, payload=payload, params=params)
  img = cv2.imdecode(np.fromstring(imgpath, np.uint8), cv2.IMREAD_UNCHANGED)
  img = cv2.resize(img, (512,512))
  img_array = np.expand_dims(np.asarray(img), axis = 0)

  model.set_tensor(input_index, img_array)
  model.invoke()
  detection_boxes = model.get_tensor(output_details[0]['index'])
  return detection_boxes[0][0]
  # for result in request.payload:
  #   bounding_boxes = result.image_object_detection.bounding_box
  #
  # return bounding_boxes

def crop_image(imgpath, bounding_box):
  image = cv2.imdecode(np.fromstring(imgpath, np.uint8), cv2.IMREAD_UNCHANGED)
  (h, w) = image.shape[:2]

  # startX = bounding_box.normalized_vertices[0].x
  # startY = bounding_box.normalized_vertices[0].y
  # endX = bounding_box.normalized_vertices[1].x
  # endY = bounding_box.normalized_vertices[1].y
  startX, endX = bounding_box[1], bounding_box[3]
  startY, endY = bounding_box[0], bounding_box[2]

  startX = int(startX * w) if startX >= 0 else 0
  startY = int(startY * h) if startY >= 0 else 0
  endX = int(endX * w)
  endY = int(endY * h)


  cropped_image = image[startY:endY, startX:endX]
  # print("cropped_image = {}".format(cropped_image))

  return cropped_image

def get_text(content, path_json):

  os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = path_json

  client = vision.ImageAnnotatorClient()

  image = vision.Image(content=content)
  response = client.text_detection(image=image)
  texts = response.text_annotations

  df = pd.DataFrame(columns = ['locale', 'description'])

  for text in texts:
    if re.search(r'^[a-zA-Z]+$', text.locale):
      df = df.append({'locale': text.locale,
                    'description' : text.description},
                ignore_index=True)
    else:
      break

  # print('extracted df : {}'.format(df)) # Debug
  # print('df["description"] : {}'.format(df['description'].str.split('\n')[0]))
  try :
      a = df['description'].str.split('\n')[0]
      return a
  except :
      print('no text detected (cloud vision)')
      return None

def get_text_1(extract):

  keys = ['no_ktp', 'name']

  df = pd.DataFrame(columns = keys)
  dict_ktp = {key: None for key in keys}

  try :
      for word in extract:

        word = word.replace(')', '1')
        word = word.replace('l', '1')

        if re.search(r'\b\d(?: ?\d){15}\b', word):
          array = re.findall(r'\b\d(?: ?\d){15}\b', word)
          for arr in array:
            if len(arr) == 16:
              dict_ktp['no_ktp'] = str(arr)
            else :
              dict_ktp['no_ktp'] = str.arr.replace(' ','')

        if re.search(r'^[A-Z \W]+$', word):
          dict_ktp['name'] = re.sub(r'[^\w]', ' ', word).strip()

      return df.append(dict_ktp, ignore_index=True)
  except :
      return df

def get_text_2(extract):

  keys = ['no_ktp', 'name', 'place_of_birth', 'birth_date', 'gender']

  df = pd.DataFrame(columns = keys)
  dict_ktp = {key: None for key in keys}

  if extract is None :
      return df

  # try :
  for idx, word in enumerate(extract):

    word = word.replace(')', '1')
    word = word.replace('l', '1')

    if re.search(r'\b\d(?: ?\d){15}\b', word):
      array = re.findall(r'\b\d(?: ?\d){15}\b', word)
      for arr in array:
        # print('arr = {}'.format(arr)) # Debug
        # print('len(arr) = {}'.format(len(arr)))
        if len(arr) == 16:
          dict_ktp['no_ktp'] = str(arr)
        else :
          dict_ktp['no_ktp'] = str(arr).replace(' ','')

    if re.search(r'Nama', word):
      index = idx + 1
    try:
      if index == idx:
        if re.search(r'^[A-Z \W]+$', word): # For searching names, are digits necessary?
          dict_ktp['name'] = re.sub(r'[^\w]', ' ', word).strip()
      if idx == index+1:
        if re.search(r'^[A-Z \W]+$', word):
          dict_ktp['name'] = dict_ktp.get('name') + ' ' + re.sub(r'[^\w]', ' ', word).strip()

    except:

      None

    if re.search(r'\d{2}\W\d{2}\W\d{4}', word):
      if re.search(r'[A-Z]+[A-Z]+', word):

        array = re.findall(r'[A-Z]+[A-Z]+', word)
        arr   = re.findall(r'\d{2}\W\d{2}\W\d{4}', word)
        dict_ktp['place_of_birth'] = ' '.join([str(elem) for elem in array])
        dict_ktp['birth_date'] = '/'.join([str(v) for elem in arr for v in re.findall(r"[\w']+", elem)])
        try : # Sometimes the systems mktime is limited to some starting year
            dict_ktp['birth_date'] = time.mktime(time.strptime(dict_ktp['birth_date'], "%d/%m/%Y"))
        except : # If we fail to recognize the year, set it to 1/1/1970
            dict_ktp['birth_date'] = time.mktime(time.strptime('1/1/1970', '%d/%m/%Y'))

    if re.search("^PEREM|.*PUAN", word):
      dict_ktp['gender'] = 'FEMALE'

    if re.search("LAKI", word):
      dict_ktp['gender'] = 'MALE'
  return df.append(dict_ktp, ignore_index=True)
  # except :
  #     return df

def dataframe1(imgpath, pathJSON):
  content = read_image(imgpath)
  # response = get_prediction(content, '613609637569', 'IOD1451511479315464192')
  response = get_prediction(imgpath, bbox)
  cropped_image = crop_image(imgpath, response)

  is_success, im_buf_arr = cv2.imencode(".jpg", cropped_image)
  content = im_buf_arr.tobytes()

  text = get_text(content, pathJSON)

  df = get_text_1(text)
  return df

def dataframe2(imgpath, pathJSON):
  content = read_image(imgpath)

  text = get_text(content, pathJSON)
  # print('dataframe2 ; text = {}'.format(text)) # Debug

  df = get_text_2(text)
  # print('dataframe2 ; df = {}'.format(df)) # Debug

  return df

def get_extract(pathimage, pathjson):
  df = dataframe2(pathimage, pathjson)
  # print('df = {}'.format(df)) # Debug

  try :
      if df['name'][0] != None or df['no_ktp'][0] != None:
        df1 = dataframe1(pathimage, pathjson)
        if df['name'][0] == None:
          df['name'] = df1['name']
        if df['no_ktp'][0] == None:
          df['no_ktp'] = df1['no_ktp']

        return df
      else:
        return df
  except :
      return df

os.environ["GOOGLE_APPLICATION_CREDENTIALS"]="q-hope-dd17dc6b88bb.json"
os.environ["PROJECT_ID"]="613609637569"

pathJson = 'q-hope-dd17dc6b88bb.json'
